{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xY4KuZUbq83Q"
   },
   "source": [
    "# Finetune Pix2Struct model on Synthetic Bootstrap dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jT6iC6BDrB9i"
   },
   "source": [
    "## Setup Envirnoment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jc7bhkoMEtq3",
    "outputId": "1b4cfd0e-eed8-44f1-9e8b-e8838006a2d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers==4.36.2 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers==4.36.2) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from transformers==4.36.2) (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/software-current/2023.06/x86_64/generic/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from transformers==4.36.2) (1.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers==4.36.2) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/software-current/2023.06/x86_64/generic/software/PyYAML/6.0-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers==4.36.2) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers==4.36.2) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers==4.36.2) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n",
      "  Using cached tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from transformers==4.36.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from transformers==4.36.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->transformers==4.36.2) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->transformers==4.36.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->transformers==4.36.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->transformers==4.36.2) (2023.5.7)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "Successfully installed tokenizers-0.15.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/software-current/2023.06/x86_64/generic/software/Python/3.11.3-GCCcore-12.3.0/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.36.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "901j04acrHxe",
    "outputId": "14915fe8-a662-4680-c657-fe65b4f87cc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The scripts wandb and wb are installed in '/mnt/home/seyeon/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers in /mnt/home/seyeon/.local/lib/python3.11/site-packages (4.51.0.dev0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wandb in /mnt/home/seyeon/.local/lib/python3.11/site-packages (0.19.9)\n",
      "Requirement already satisfied: tqdm in /mnt/home/seyeon/.local/lib/python3.11/site-packages (4.67.1)\n",
      "Collecting Pillow\n",
      "  Downloading pillow-11.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (19.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/software-current/2023.06/x86_64/generic/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from torchvision) (1.25.1)\n",
      "Requirement already satisfied: torch==2.6.0 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: filelock in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (4.13.0)\n",
      "Requirement already satisfied: networkx in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/software-current/2023.06/x86_64/generic/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from transformers) (0.30.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/software-current/2023.06/x86_64/generic/software/PyYAML/6.0-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: click in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from wandb) (3.8.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: pydantic<3 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from wandb) (2.11.1)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from wandb) (2.25.0)\n",
      "Requirement already satisfied: setproctitle in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /opt/software-current/2023.06/x86_64/generic/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/site-packages (from wandb) (67.7.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from pydantic<3->wandb) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/software-current/2023.06/x86_64/amd/zen2/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from jinja2->torch==2.6.0->torchvision) (2.1.3)\n",
      "Installing collected packages: Pillow, nltk, torchvision\n",
      "\u001b[33m  WARNING: The script nltk is installed in '/mnt/home/seyeon/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed Pillow-11.2.0 nltk-3.9.1 torchvision-0.21.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/software-current/2023.06/x86_64/generic/software/Python/3.11.3-GCCcore-12.3.0/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install torchvision nltk wandb tqdm Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGk1Y2ea-3vS"
   },
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9qulzbyd-1GC"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os\n",
    "import zipfile\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import re\n",
    "from transformers import Pix2StructForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers.optimization import Adafactor, get_cosine_schedule_with_warmup\n",
    "from pathlib import Path\n",
    "from nltk import edit_distance\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
    "from torch.utils.data import random_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZ3TJ2yzBAs0"
   },
   "source": [
    "## Define variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Rrjr3uhaBDqp"
   },
   "outputs": [],
   "source": [
    "# G_DRIVE_FOLDER = '/content/drive/MyDrive/Datasets/'\n",
    "\n",
    "# DATASET_NAME = 'synthBootstrap_mini'\n",
    "# ZIP_NAME = DATASET_NAME + '.zip'\n",
    "# DESTINATION_FOLDER= 'data/'\n",
    "# DATASET_FOLDER = DESTINATION_FOLDER + DATASET_NAME\n",
    "\n",
    "# HTML_FILES_FOLDER = DESTINATION_FOLDER + \"html/\"\n",
    "# home/seyeon/data/synthBootstrap_mini/html\n",
    "\n",
    "FOLDER_CHECKPOINTS = ''\n",
    "DATASET_NAME = 'synthBootstrap_mini/'\n",
    "ZIP_NAME = DATASET_NAME + '.zip'\n",
    "DESTINATION_FOLDER= 'data/'\n",
    "DATASET_FOLDER = DESTINATION_FOLDER + DATASET_NAME\n",
    "HTML_FILES_FOLDER = DATASET_FOLDER + \"html/\"\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = \"Pix2Struct_SynthBootstrap\"\n",
    "\n",
    "MAX_SENTENCE_LEN = 4096\n",
    "\n",
    "CHUNK_LENGTH =  1024\n",
    "CONTEXT_OVERLAP_LENGTH = 256\n",
    "\n",
    "MAX_PATCHES = 1024\n",
    "\n",
    "DEBUG = False\n",
    "VERBOSE = True\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WARMUP_STEPS = 1000\n",
    "MAX_EPOCHS = 200\n",
    "LR = 1e-4\n",
    "CHECK_VAL_EVERY_N_EPOCH = 5\n",
    "GRADIENT_CLIP_VAL = 1.0\n",
    "ACCUMULATE_GRAD_BATCHES = 8 / BATCH_SIZE\n",
    "\n",
    "TRAIN_SET_PERCENTAGE = 0.88\n",
    "VALID_SET_PERCENTAGE = 0.02 # Use 20 for validation\n",
    "# TEST_SET_PERCENTAGE is 1 - TRAIN_SET_PERCENTAGE - VALID_SET_PERCENTAGE # Use 100 for test\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "\n",
    "LOAD_FROM_CHECKPOINT = False\n",
    "LAST_CHECKPOINT_NAME = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UVN0Pk4IuVYN"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKC06Ai1Xhcl",
    "outputId": "b222e610-dd40-45a9-8541-d395d622eec5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_N_CHUNKS_PER_SENTENCE 5\n"
     ]
    }
   ],
   "source": [
    "MAX_N_CHUNKS_PER_SENTENCE = 1 + (MAX_SENTENCE_LEN - CHUNK_LENGTH) // (CHUNK_LENGTH - CONTEXT_OVERLAP_LENGTH)\n",
    "print(\"MAX_N_CHUNKS_PER_SENTENCE\", MAX_N_CHUNKS_PER_SENTENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kflo6stPSGhT"
   },
   "source": [
    "\n",
    "## Load Synthetic Bootstrap Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIyXwQultNqy"
   },
   "source": [
    "## Load Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tokenizers==0.21.0\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from tokenizers==0.21.0) (0.30.1)\n",
      "Requirement already satisfied: filelock in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/software-current/2023.06/x86_64/generic/software/PyYAML/6.0-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (6.0)\n",
      "Requirement already satisfied: requests in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/home/seyeon/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/software-current/2023.06/x86_64/amd/zen4/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (2023.5.7)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 16] Device or resource busy: '.nfs7521888e86192a7e00000001'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/software-current/2023.06/x86_64/generic/software/Python/3.11.3-GCCcore-12.3.0/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tokenizers==0.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "a15823da8b6f4de88720c7e8d583ad55",
      "75ceaa2e86914cf392de027b89e8db1a",
      "5ac6a0c5f3884a97a668bd94e2c99247",
      "a7482b7279d54b6aba4dc07d8f68694a",
      "c432eca2b0174148bc416e77f77c32b6",
      "39888333744e4904b07b40a6ed8dfce6",
      "4cba271698ee4905b98d962ae715a9d4",
      "737c072add7e4216bd0edb23f70dfaf3",
      "30052275c23c46419b8514b32e0d00bb",
      "a2054c99644a46a7ae2c6082ded87f88",
      "1ddb3ecbc2e743438926f3e088659976",
      "4b62856cbf364e8e832d46d8cfa51b0c",
      "6675867d1a0641a08a808f134c30f6ea",
      "6539bb1b685b4ef5b19bf6753c00cdc3",
      "70fe49be4d92429b9bce8023dfd07961",
      "340e901240d645fabc7766cc6bfe66d4",
      "faba4ea1b56d433bbb7c7ffa622563da",
      "11c38a1ceff94799b52f5e0ae8b84969",
      "980b66fd9db94e6387e2a3695266dcd2",
      "31779c12e1504311aa481206c83a2163",
      "49f2463952c242d48150894057246cf6",
      "cc74223b6eb24b8f91e8c291adb8f02a",
      "8743786ccb424b1d805912ed49b5d2ec",
      "59ce1cc6421949aeb6994bccacafd2a6",
      "c610f62ad52b43cfbf829d22d09c3ec4",
      "a164951cb80a4077b5a96ea73ba360eb",
      "fcb5645709fd4d3b8715ddee208e0223",
      "52b56e2fa97147acaf348b050be63550",
      "54be443c0c9e441296dd7cdf67db46aa",
      "b0e0482079c048a3847b3043fd430ec3",
      "4c399af2dafe432f87fd4546616bab47",
      "191b60c5726c4002a93e0d622c2b0698",
      "a748bdd7655247b9b77057e77149922a",
      "df22ab40b1054b9d905a62a420ce5348",
      "2ebc30057a344280b18311f35d148323",
      "1fb50697ceff45aeb2d8cac2cee2c22c",
      "ab4cea35df204af0911ffeaff9608f43",
      "161589ef49a64926834eada256388668",
      "0f5444713b094d54ad7e9b613ab12d25",
      "10d06787e2b34435bdd33e549a980aee",
      "4e8222a9fb844ab59eb9251ee5e9cd92",
      "0f10bb55ee654fb7a89868ae347d7514",
      "06a1c9b06e104cc0804d0b6c217e2997",
      "fb7fad66696542d3a18d1333221d3427",
      "997cf585fc654ae38ad04a196b1c78d0",
      "1621b516d9ec41f9b0dc0f3b7e23feb7",
      "15e38778004b42b1aed4e42e05e6b9e1",
      "8760eb617eb2439fba4a92273f3bca56",
      "4cc0dd0670054510b8e8b06756fff6a3",
      "2375fafdc51c4616ad42de83731cb051",
      "54a1747a9bd04718958c2ce6082547a3",
      "7aef95b240a24ba482ff25d1ff1bbc39",
      "ec408e1374314eaeb222569c653fcb2c",
      "10e915f0c9e24a6e953203bd0283f094",
      "5d1234c1b99d4348b798183b3bf42990",
      "63da399945314f728f3e3bc83b515bc1",
      "88edc231537a478dbc3d2813519fd21f",
      "fb7588cb84334eebbe741c2a74087267",
      "d807979736ac4efb88adfe885df15b0a",
      "5e63695c36bb43068e7405a2a4230255",
      "cf8c028c3b1a434fa5cfb3a2498d8403",
      "ac4dc770d30844ea8a225714653ad2a6",
      "5f62f8a1831743f3ab7d54ab6dffbd76",
      "44a0c75207414dadb7eaec22678391e4",
      "8161314abb844376b605c9b2e1b5f9fb",
      "88b0140c32e140339325d6eae0880ebd",
      "38271e0f9f6f41958163672d0201d6ab",
      "d45d65b44fca4b8b8d5ba0ab653cc1fa",
      "4bc5323f5ffa4891ae7ac3a361489e6e",
      "e4511bb6e56c46b8a1daef8e3275442a",
      "95329f0d24984b40aa7eb82114bf5591",
      "7a61dc6ad0c848168e4a68cc0970aebf",
      "1f1c33aa528e4a43bfb298957cfe2fee",
      "c9c593d7ee604fa19d7c58414facad54",
      "fe96538b9f4c452c90ca4cbca734b9fc",
      "a003c848e5c7459d8003a9da6628994d",
      "7faf095de4ea48a08ad56742ffd6311f"
     ]
    },
    "id": "15QM1CZQtRWr",
    "outputId": "18ce8004-bb03-4e54-b5ff-2fd885547224"
   },
   "outputs": [],
   "source": [
    "\n",
    "repo_id = \"google/pix2struct-base\"\n",
    "processor = AutoProcessor.from_pretrained(repo_id)\n",
    "model = Pix2StructForConditionalGeneration.from_pretrained(repo_id, is_encoder_decoder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vyJVirgV8VN"
   },
   "source": [
    "## Create Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK0eTFCl01vq"
   },
   "source": [
    "### Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5cFoFlit1hGN"
   },
   "outputs": [],
   "source": [
    "def round_floats_in_text(text, precision=0):\n",
    "    # match float numbers with 2 or more decimal places in the text\n",
    "    pattern = r\"\\b\\d+\\.\\d{2,}\\b\"\n",
    "\n",
    "    def replace(match):\n",
    "        float_number = float(match.group())\n",
    "        return f\"{float_number:.{precision}f}\"\n",
    "\n",
    "    text = re.sub(pattern, replace, text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3DgqJJwSKsAj"
   },
   "outputs": [],
   "source": [
    "def remove_html_comments(text):\n",
    "    # match html comments\n",
    "    pattern = r\"<!--.*?-->\"\n",
    "\n",
    "    text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3Jj8_5IWClbz"
   },
   "outputs": [],
   "source": [
    "def preprocess_html_file(html_text):\n",
    "    text_cleaned = html_text.replace('\\n', ' ')\n",
    "    text_cleaned_without_multiple_spaces = re.sub(r'\\s+', ' ', text_cleaned)\n",
    "    text_without_comments = remove_html_comments(text_cleaned_without_multiple_spaces)\n",
    "    text_without_long_floats = round_floats_in_text(text_without_comments)\n",
    "    return text_without_long_floats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxls5fsNDAXL"
   },
   "source": [
    "### Find max sentence length and new unknown tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1239 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Average token length: 1209.12\n",
      "📐 Standard deviation: ±175.31\n",
      "📈 Max: 1649, 📉 Min: 612\n",
      "💡 Range covering ~68% of data: 1034 to 1384\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load your tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "html_dir = \"data/pix2code/html\"\n",
    "token_lengths = []\n",
    "\n",
    "# Tokenize and collect lengths\n",
    "for fname in os.listdir(html_dir):\n",
    "    if fname.endswith(\".html\"):\n",
    "        with open(os.path.join(html_dir, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "            html = f.read()\n",
    "            tokens = tokenizer(html, truncation=False, add_special_tokens=True)\n",
    "            token_lengths.append(len(tokens[\"input_ids\"]))\n",
    "\n",
    "# Convert to numpy array\n",
    "token_lengths = np.array(token_lengths)\n",
    "\n",
    "# Compute statistics\n",
    "avg_len = np.mean(token_lengths)\n",
    "std_dev = np.std(token_lengths)\n",
    "min_len = np.min(token_lengths)\n",
    "max_len = np.max(token_lengths)\n",
    "\n",
    "print(f\"📊 Average token length: {avg_len:.2f}\")\n",
    "print(f\"📐 Standard deviation: ±{std_dev:.2f}\")\n",
    "print(f\"📈 Max: {max_len}, 📉 Min: {min_len}\")\n",
    "print(f\"💡 Range covering ~68% of data: {avg_len - std_dev:.0f} to {avg_len + std_dev:.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YEhd7D32SZrf",
    "outputId": "2cebc0b7-ca00-43fa-c8b8-77675b8e2eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length = 3995\n",
      "Number of new tokens = 543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "# Find max length\n",
    "all_paths = os.listdir(HTML_FILES_FOLDER)\n",
    "\n",
    "max_length = 0\n",
    "\n",
    "# Read text files and add new tokens to dictionary\n",
    "tokens_to_add = set()\n",
    "for html_file_path in all_paths:\n",
    "    with open(HTML_FILES_FOLDER + html_file_path, \"r\") as reader:\n",
    "        splitted_text = processor.tokenizer(preprocess_html_file(reader.read())).tokens()\n",
    "        tokens_to_add = tokens_to_add.union(set(splitted_text))\n",
    "\n",
    "        # Check if the current sentence has the largest number of tokens\n",
    "        if len(splitted_text) > max_length:\n",
    "            max_length = len(splitted_text)\n",
    "\n",
    "print(f\"Max sentence length = {max_length}\")\n",
    "\n",
    "newly_added_num = processor.tokenizer.add_tokens(list(tokens_to_add))\n",
    "print(f\"Number of new tokens = {newly_added_num}\")\n",
    "\n",
    "# Resize the model's token embeddings if there are new tokens\n",
    "if newly_added_num > 0:\n",
    "    model.decoder.resize_token_embeddings(len(processor.tokenizer))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from torch.nn import functional as F\n",
    "# import torch\n",
    "\n",
    "# # Resize token embeddings (but don't rely on automatic init)\n",
    "# old_embeddings = model.decoder.get_input_embeddings().weight.data\n",
    "# old_vocab_size, hidden_size = old_embeddings.shape\n",
    "\n",
    "# # Perform resize manually\n",
    "# model.decoder.resize_token_embeddings(len(processor.tokenizer))\n",
    "\n",
    "# # New embedding layer\n",
    "# new_embeddings = model.decoder.get_input_embeddings().weight.data\n",
    "# new_vocab_size = new_embeddings.size(0)\n",
    "\n",
    "# # Number of newly added tokens\n",
    "# num_new_tokens = new_vocab_size - old_vocab_size\n",
    "\n",
    "# if num_new_tokens > 0:\n",
    "#     # Get the mean and std of existing embeddings\n",
    "#     mean = old_embeddings.mean(dim=0)\n",
    "#     cov = torch.cov(old_embeddings.T)  # Use T to get shape (hidden, hidden)\n",
    "\n",
    "#     # Sample new embeddings using multivariate normal\n",
    "#     new_embs = torch.distributions.MultivariateNormal(mean, covariance_matrix=cov).sample((num_new_tokens,))\n",
    "    \n",
    "#     # Replace the new part of the embedding matrix\n",
    "#     new_embeddings[old_vocab_size:] = new_embs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfKTQ5aMPtfN"
   },
   "source": [
    "### Split files into training - validation - test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJJvSGk00jfL",
    "outputId": "90590f43-82f9-4968-bb7e-5cae775f6680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SET size = 880\n",
      "VALID_SET size = 20\n",
      "TEST_SET size = 100\n"
     ]
    }
   ],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "random.shuffle(sorted(all_paths))\n",
    "\n",
    "train_len = int(TRAIN_SET_PERCENTAGE * len(all_paths))\n",
    "valid_len = int(VALID_SET_PERCENTAGE * len(all_paths))\n",
    "\n",
    "train_paths = all_paths[:train_len]\n",
    "valid_paths = all_paths[train_len:train_len+valid_len]\n",
    "test_paths = all_paths[train_len+valid_len:]\n",
    "\n",
    "print(f\"TRAIN_SET size = {len(train_paths)}\")\n",
    "print(f\"VALID_SET size = {len(valid_paths)}\")\n",
    "print(f\"TEST_SET size = {len(test_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EiExjyGE1cla"
   },
   "outputs": [],
   "source": [
    "class SythBootstrapTrainingDataset(Dataset):\n",
    "    # This is a modification of the dataset used for validation and testing\n",
    "    # In this one the sentences are already split into chunks, already having\n",
    "    # the context from the previous chunk, empty chunks are discarded\n",
    "    def __init__(self, root_dir, transform, text_files_paths):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.text_files_paths = text_files_paths\n",
    "\n",
    "        self.max_patches = MAX_PATCHES\n",
    "        self.max_length = MAX_SENTENCE_LEN\n",
    "        self.ignore_id = -100\n",
    "\n",
    "        self.data = []\n",
    "        self.images_encoding = []\n",
    "\n",
    "        for text_file in tqdm(text_files_paths):\n",
    "            image_file = text_file.replace('.html', '.png')\n",
    "\n",
    "            # Directly process the text files, and save them in the ram\n",
    "            # Do the same also for images, if there is enough space in memory\n",
    "            text_file_path = os.path.join(root_dir + \"html/\", text_file)\n",
    "            image_file_path = os.path.join(root_dir + \"images/\", image_file)\n",
    "\n",
    "            # Each data entry has the following structure\n",
    "            # labels, image_encoding_idx, part\n",
    "\n",
    "            # image_encoding_idx points to an entry of images_encoding, which contains attention_mask and flattened_patches for the image\n",
    "            # Since a single image is used for multiple slices of the same text, this approach is used to save memory\n",
    "\n",
    "            # Load image\n",
    "            image = Image.open(image_file_path).convert('RGB')\n",
    "\n",
    "            if DEBUG:\n",
    "                image.show()\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            encoding = processor(images=image, max_patches=self.max_patches, return_tensors=\"pt\")\n",
    "            encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
    "\n",
    "            self.images_encoding.append(encoding)\n",
    "            image_encoding_idx = len(self.images_encoding) - 1\n",
    "\n",
    "            # Load text\n",
    "            with open(text_file_path, 'r') as f:\n",
    "                text = f.read()\n",
    "                text_cleaned = preprocess_html_file(text)\n",
    "\n",
    "            if DEBUG:\n",
    "              print(\"text:\")\n",
    "              print(text)\n",
    "              print(\"\\n\\n\\ntext_cleaned:\")\n",
    "              print(text_cleaned)\n",
    "\n",
    "            input_ids = processor.tokenizer(\n",
    "                text_cleaned,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).input_ids\n",
    "\n",
    "            input_ids_slices = []\n",
    "\n",
    "            start_index = 0\n",
    "            end_index = CHUNK_LENGTH\n",
    "            while end_index <= MAX_SENTENCE_LEN:\n",
    "                input_ids_slices.append(input_ids[:, start_index:end_index])\n",
    "                start_index = end_index - CONTEXT_OVERLAP_LENGTH\n",
    "                end_index = start_index + CHUNK_LENGTH\n",
    "\n",
    "            for part, input_ids_slice in enumerate(input_ids_slices):\n",
    "                labels = input_ids_slice.squeeze().clone()\n",
    "\n",
    "                labels[labels == processor.tokenizer.pad_token_id] = self.ignore_id  # model doesn't need to predict pad token\n",
    "\n",
    "                # Skip slices with only padding tokens, ignore context from the previous chunk\n",
    "                if part != 0 and all(x == self.ignore_id for x in labels[CONTEXT_OVERLAP_LENGTH:]):\n",
    "                    continue\n",
    "\n",
    "                # labels, image_encoding_idx, part\n",
    "                # Save them as int32 to save ram memory\n",
    "                self.data.append((labels.to(torch.int32), image_encoding_idx, part))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        labels, image_encoding_idx, part = self.data[idx]\n",
    "        encoding = self.images_encoding[image_encoding_idx]\n",
    "        encoding[\"labels\"] = labels.to(torch.int64)\n",
    "\n",
    "        return encoding, part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oMC2-OYYWB75"
   },
   "outputs": [],
   "source": [
    "class SythBootstrapDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform, text_files_paths):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.text_files_paths = text_files_paths\n",
    "\n",
    "        self.max_patches = MAX_PATCHES\n",
    "        self.max_length = MAX_SENTENCE_LEN\n",
    "        self.ignore_id = -100\n",
    "\n",
    "        self.encodings = []\n",
    "\n",
    "        for text_file in tqdm(text_files_paths):\n",
    "            image_file = text_file.replace('.html', '.png')\n",
    "\n",
    "            # Directly process the text files, and save them in the ram\n",
    "            # Do the same also for images, if there is enough space in memory\n",
    "            text_file_path = os.path.join(root_dir + \"html/\", text_file)\n",
    "            image_file_path = os.path.join(root_dir + \"images/\", image_file)\n",
    "\n",
    "            # Load image\n",
    "            image = Image.open(image_file_path).convert('RGB')\n",
    "\n",
    "            if DEBUG:\n",
    "                image.show()\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            encoding = processor(images=image, max_patches=self.max_patches, return_tensors=\"pt\")\n",
    "            encoding = {k:v.squeeze() for k,v in encoding.items()}\n",
    "\n",
    "            # Load text\n",
    "            with open(text_file_path, 'r') as f:\n",
    "                text = f.read()\n",
    "                text_cleaned = preprocess_html_file(text)\n",
    "\n",
    "            if DEBUG:\n",
    "              print(\"text:\")\n",
    "              print(text)\n",
    "              print(\"\\n\\n\\ntext_cleaned:\")\n",
    "              print(text_cleaned)\n",
    "\n",
    "            input_ids = processor.tokenizer(\n",
    "                text_cleaned,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).input_ids\n",
    "\n",
    "            labels = input_ids.squeeze().clone()\n",
    "            labels[labels == processor.tokenizer.pad_token_id] = self.ignore_id  # model doesn't need to predict pad token\n",
    "\n",
    "            encoding[\"labels\"] = labels.to(torch.int32)\n",
    "\n",
    "            # For each sample save directly the encoding of both text and image\n",
    "            self.encodings.append(encoding)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encodings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WulOgKwb1aNh",
    "outputId": "8ca82a60-2d8f-4184-b33c-7a77dafa3e3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 880/880 [00:43<00:00, 20.30it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 19.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Transformations for the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # convert PIL Image to PyTorch Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # normalize for pretrained models\n",
    "])\n",
    "\n",
    "# Instantiate the CustomDataset\n",
    "train_dataset = SythBootstrapTrainingDataset(DATASET_FOLDER, transform, train_paths)\n",
    "val_dataset = SythBootstrapDataset(DATASET_FOLDER, transform, valid_paths)\n",
    "\n",
    "# Use DataLoader for batching and shuffling\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=10, shuffle=False) # Use 10 as batch for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJbcAvt2eSvb",
    "outputId": "991efeca-d66a-408f-d8a5-15a8557a07dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader size = 692\n",
      "val_dataloader size = 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_dataloader size = {len(train_dataloader)}\")\n",
    "print(f\"val_dataloader size = {len(val_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7DngCr1FJQJ"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zkCJQz_GEM4W"
   },
   "outputs": [],
   "source": [
    "START_TOKEN_ID = PAD_TOKEN_ID = processor.tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWSsn0vr1mV2"
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mq6Y22hDqn3x"
   },
   "outputs": [],
   "source": [
    "def move_to_device(data):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [move_to_device(x) for x in data]\n",
    "    elif isinstance(data, dict):\n",
    "        return {k: move_to_device(v) for k, v in data.items()}\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.to(DEVICE)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JRX7UDLE4Nh8"
   },
   "outputs": [],
   "source": [
    "def create_extended_attention_mask_for_decoder_with_context(input_shape, attention_mask, part):\n",
    "    device = attention_mask.device\n",
    "    batch_size, seq_length = input_shape\n",
    "    seq_ids = torch.arange(seq_length, device=device)\n",
    "\n",
    "    causal_mask = seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None]\n",
    "\n",
    "    # Expand part to have the same shape as the relevant slice of causal_mask\n",
    "    part_expanded = part.unsqueeze(-1).unsqueeze(-1).expand(-1, seq_length, CONTEXT_OVERLAP_LENGTH)\n",
    "\n",
    "    # Create a mask with ones where part is not zero\n",
    "    context_mask = (part_expanded != 0).float()\n",
    "\n",
    "    # Apply the context_mask to the corresponding part of causal_mask\n",
    "    causal_mask[:, :, :CONTEXT_OVERLAP_LENGTH] = causal_mask[:, :, :CONTEXT_OVERLAP_LENGTH] * (1 - context_mask) + context_mask\n",
    "\n",
    "    # in case past_key_values are used we need to add a prefix ones mask to the causal mask\n",
    "    causal_mask = causal_mask.to(attention_mask.dtype)\n",
    "\n",
    "    if causal_mask.shape[1] < attention_mask.shape[1]:\n",
    "        print(\"!!should not enter here in my case!!\")\n",
    "        prefix_seq_len = attention_mask.shape[1] - causal_mask.shape[1]\n",
    "        causal_mask = torch.cat(\n",
    "            [\n",
    "                torch.ones((batch_size, seq_length, prefix_seq_len), device=device, dtype=causal_mask.dtype),\n",
    "                causal_mask,\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "\n",
    "    extended_attention_mask = causal_mask[:, :, :] * attention_mask[:, None, :]\n",
    "    return extended_attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8RMB16MR53fK"
   },
   "outputs": [],
   "source": [
    "def get_attention_mask(decoder_input_ids, part):\n",
    "    # decoder_attention_mask = (decoder_input_ids.ne(PAD_TOKEN_ID).float())\n",
    "    decoder_attention_mask = (decoder_input_ids != processor.tokenizer.pad_token_id).long()\n",
    "\n",
    "\n",
    "    # always attend on first token\n",
    "    decoder_attention_mask[:, 0] = 1\n",
    "\n",
    "    # Expand part to have the same shape as the relevant slice of decoder_attention_mask\n",
    "    part_expanded = part.unsqueeze(-1).expand(-1, CONTEXT_OVERLAP_LENGTH)\n",
    "\n",
    "    # Create a mask with ones where part is not zero\n",
    "    context_mask = (part_expanded != 0).float()\n",
    "\n",
    "    # Apply the context_mask to the corresponding part of decoder_attention_mask\n",
    "    decoder_attention_mask[:, 0:CONTEXT_OVERLAP_LENGTH] = decoder_attention_mask[:, 0:CONTEXT_OVERLAP_LENGTH] * (1 - context_mask) + context_mask\n",
    "\n",
    "    return decoder_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "I4EwQ8iP8a9I"
   },
   "outputs": [],
   "source": [
    "def shift_right_modified(input_ids, decoder_starting_token_idx):\n",
    "\n",
    "    # shift inputs to the right\n",
    "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
    "    shifted_input_ids[..., 1:] = input_ids[..., :-1].clone()\n",
    "    shifted_input_ids[..., 0] = decoder_starting_token_idx\n",
    "\n",
    "    # replace possible -100 values in labels by `pad_token_id`\n",
    "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, PAD_TOKEN_ID)\n",
    "\n",
    "    return shifted_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Mvsy0HBseyzQ"
   },
   "outputs": [],
   "source": [
    "def get_decoder_input_ids(labels_chunk, start_id):\n",
    "    return shift_right_modified(labels_chunk, start_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2LqZyYsWOywQ"
   },
   "outputs": [],
   "source": [
    "def get_decoder_input_ids_and_attention_mask(labels, part):\n",
    "    decoder_input_ids = get_decoder_input_ids(labels, START_TOKEN_ID)\n",
    "    decoder_attention_mask = get_attention_mask(decoder_input_ids, part)\n",
    "    extended_decoder_attention_mask = create_extended_attention_mask_for_decoder_with_context(decoder_input_ids.shape, decoder_attention_mask, part)\n",
    "\n",
    "    return decoder_input_ids, extended_decoder_attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEt-owxM1puj"
   },
   "source": [
    "### Main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1j0_8Yk6Gk4-"
   },
   "outputs": [],
   "source": [
    "def train_model(config, processor, model, train_dataloader, val_dataloader):\n",
    "    # Extract configuration values\n",
    "    lr = config.get(\"lr\")\n",
    "    max_epochs = config.get(\"max_epochs\")\n",
    "    num_warmup_steps = config.get(\"num_warmup_steps\")\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = Adafactor(model.parameters(), scale_parameter=False, relative_step=False, lr=lr, weight_decay=1e-05)\n",
    "\n",
    "    # Use total steps (i.e., max_epochs * length_of_train_data)\n",
    "    total_steps = max_epochs * len(train_dataloader)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=num_warmup_steps,\n",
    "                                                num_training_steps=total_steps)\n",
    "\n",
    "    global_step = 0  # to keep track of total steps\n",
    "    epoch_start = 0\n",
    "\n",
    "    if LOAD_FROM_CHECKPOINT:\n",
    "        print(\"Loading model from checkpoint:\", LAST_CHECKPOINT_NAME)\n",
    "        checkpoint = torch.load(LAST_CHECKPOINT_NAME)\n",
    "        model.resize_token_embeddings(50244) ### retrain\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        epoch_start = checkpoint[\"epoch\"] + 1\n",
    "        global_step = checkpoint[\"global_step\"] + 1\n",
    "        wandb_run_id = checkpoint[\"wandb_run_id\"]\n",
    "\n",
    "        # Resume the WandB run\n",
    "        wandb.init(project=\"Pix2Struct\", name=\"run-\" + EXPERIMENT_NAME, config=config,     resume=\"must\", id=\"iaegqr6z\")\n",
    "    else:\n",
    "        wandb.init(project=\"Pix2Struct\", name=\"run-\" + EXPERIMENT_NAME, config=config)\n",
    "\n",
    "    epoch_last = epoch_start + max_epochs - 1\n",
    "    for epoch in range(epoch_start, epoch_start + max_epochs):\n",
    "        global_step, moving_avg_loss = training_loop(epoch, train_dataloader, model, config, optimizer, scheduler, global_step, epoch_last)\n",
    "\n",
    "        if epoch == 0 + epoch_start or epoch == epoch_last or (epoch + 1) % config.get(\"check_val_every_n_epoch\") == 0:\n",
    "            avg_bleu_score = testing_loop(val_dataloader, model, processor, config, f\"Epoch {epoch}/{epoch_last} - valid loop\")\n",
    "\n",
    "            # Save the model after each validation step\n",
    "            save_checkpoint(model, optimizer, scheduler, epoch, global_step, wandb.run.id, avg_bleu_score, EXPERIMENT_NAME, FOLDER_CHECKPOINTS)\n",
    "\n",
    "            if config.get(\"verbose\", False):\n",
    "                print(f\"Moving Avg Loss: {moving_avg_loss:.3f}\")\n",
    "                print(f\" Avg Bleu Score: {avg_bleu_score:.2f}\")\n",
    "\n",
    "            wandb.log({\"moving_avg_loss\": moving_avg_loss, \"bleu\": avg_bleu_score, **{f'lr_{i}': param_group['lr'] for i, param_group in enumerate(optimizer.param_groups)}})\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "wg6u7CI38kMU"
   },
   "outputs": [],
   "source": [
    "def training_loop(epoch, train_dataloader, model, config, optimizer, scheduler, global_step, epoch_last):\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    train_loop = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Epoch {epoch}/{epoch_last} - train loop\")\n",
    "\n",
    "    # Extract configuration values\n",
    "    accumulate_grad_batches = config.get('accumulate_grad_batches', 1)\n",
    "    gradient_clip_val = config.get(\"gradient_clip_val\")\n",
    "\n",
    "    moving_avg_loss = 0\n",
    "    alpha = 0.1 # Smoothing factor\n",
    "\n",
    "    for step, batch in train_loop:\n",
    "        encoding, part = map(move_to_device, batch)\n",
    "        labels, flattened_patches, attention_mask = encoding[\"labels\"], encoding[\"flattened_patches\"], encoding[\"attention_mask\"]\n",
    "\n",
    "        decoder_input_ids, decoder_attention_mask = get_decoder_input_ids_and_attention_mask(labels, part)\n",
    "        \n",
    "        # outputs = model(labels=labels, flattened_patches=flattened_patches, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids, decoder_attention_mask=decoder_attention_mask)\n",
    "        outputs = model(\n",
    "            labels=labels,\n",
    "            flattened_patches=flattened_patches,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        if global_step % accumulate_grad_batches == 0 or step == len(train_dataloader) - 1:\n",
    "            if gradient_clip_val:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_val)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Update the progress bar\n",
    "        train_loop.set_postfix({'loss': loss.item()}, refresh=True)\n",
    "\n",
    "        scheduler.step()\n",
    "        global_step += 1\n",
    "\n",
    "        # Update the moving average loss\n",
    "        moving_avg_loss = loss.item() if moving_avg_loss == 0 else alpha * loss.item() + (1 - alpha) * moving_avg_loss\n",
    "\n",
    "        # Log Loss after each step\n",
    "        wandb.log({\"loss\": loss.item()})\n",
    "\n",
    "    return global_step, moving_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "RXfc_whn-qJW"
   },
   "outputs": [],
   "source": [
    "# def testing_loop(testing_dataloader, model, processor, config, description):\n",
    "#     model.eval()\n",
    "#     bleu_scores = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         test_loop = tqdm(enumerate(testing_dataloader), total=len(testing_dataloader), desc=description)\n",
    "#         for i, batch in test_loop:\n",
    "#             encoding = move_to_device(batch)\n",
    "#             labels, flattened_patches, attention_mask = encoding[\"labels\"], encoding[\"flattened_patches\"], encoding[\"attention_mask\"]\n",
    "\n",
    "#             # Initialize total_outputs with zeros\n",
    "#             total_outputs = None\n",
    "#             context_from_last = None\n",
    "\n",
    "#             # Initialize a mask to track which sentences are finished\n",
    "#             finished_sentences_mask = torch.zeros(flattened_patches.size(0), dtype=torch.bool, device=flattened_patches.device)\n",
    "\n",
    "#             for iteration in range(MAX_N_CHUNKS_PER_SENTENCE):\n",
    "\n",
    "#                 generate_args = {\n",
    "#                     \"flattened_patches\": flattened_patches[~finished_sentences_mask],\n",
    "#                     \"attention_mask\": attention_mask[~finished_sentences_mask],\n",
    "#                     \"max_new_tokens\": CHUNK_LENGTH - (CONTEXT_OVERLAP_LENGTH if iteration else 0),\n",
    "#                 }\n",
    "\n",
    "#                 if iteration and context_from_last is not None:\n",
    "#                     generate_args[\"decoder_input_ids\"] = context_from_last[~finished_sentences_mask]\n",
    "\n",
    "#                 outputs = model.generate(**generate_args)\n",
    "\n",
    "#                 # Remove context overlap only from the second iteration onwards\n",
    "#                 new_chunks = outputs if iteration == 0 else outputs[:, CONTEXT_OVERLAP_LENGTH:]\n",
    "\n",
    "#                 if iteration == 0:\n",
    "#                     total_outputs = new_chunks\n",
    "#                 else:\n",
    "#                     # Update total_outputs by concatenating new chunks\n",
    "#                     new_chunks_with_padding_chunks = torch.full((flattened_patches.shape[0], new_chunks.shape[1]), PAD_TOKEN_ID, dtype=new_chunks.dtype, device=new_chunks.device)\n",
    "#                     new_chunks_with_padding_chunks[~finished_sentences_mask] = new_chunks\n",
    "#                     total_outputs = torch.cat((total_outputs, new_chunks_with_padding_chunks), dim=1)\n",
    "\n",
    "#                 # Update the finished_sentences_mask\n",
    "#                 finished_sentences_mask[~finished_sentences_mask] |= (outputs == processor.tokenizer.eos_token_id).any(dim=1)\n",
    "\n",
    "#                 # If all sentences are finished, exit the loop\n",
    "#                 if finished_sentences_mask.all():\n",
    "#                     break\n",
    "\n",
    "#                 if outputs.shape[1] < CHUNK_LENGTH:\n",
    "#                     print(\"ERROR: !! should have already exited because all sentences reached the end!!\")\n",
    "\n",
    "#                 # -1 because it will put in front a START_TOKEN automatically\n",
    "#                 context_from_last = total_outputs[:, -(CONTEXT_OVERLAP_LENGTH-1):]\n",
    "\n",
    "#             predictions = processor.tokenizer.batch_decode(total_outputs, skip_special_tokens=True)\n",
    "\n",
    "#             labels[labels == -100] = 0\n",
    "#             answers = processor.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "#             bleu_scores += [corpus_bleu([[answer]], [pred], smoothing_function=SmoothingFunction().method4) for pred, answer in zip(predictions, answers)]\n",
    "\n",
    "#             avg_bleu_score = np.mean(bleu_scores)\n",
    "#             test_loop.set_postfix(bleu_score=avg_bleu_score)\n",
    "\n",
    "#             if config.get(\"verbose\", False):\n",
    "#                 for pred, answer, bleu_score in zip(predictions, answers, bleu_scores):\n",
    "#                     tqdm.write(f\"\\nPrediction: {pred}\\n    Answer: {answer}\\n      Bleu: {bleu_score:.2f}\")\n",
    "\n",
    "\n",
    "#     return avg_bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def testing_loop(testing_dataloader, model, processor, config, description):\n",
    "#     model.eval()\n",
    "#     bleu_scores = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         test_loop = tqdm(enumerate(testing_dataloader), total=len(testing_dataloader), desc=description)\n",
    "#         for i, batch in test_loop:\n",
    "#             encoding = move_to_device(batch)\n",
    "#             labels, flattened_patches, attention_mask = encoding[\"labels\"], encoding[\"flattened_patches\"], encoding[\"attention_mask\"]\n",
    "\n",
    "#             # Initialize total_outputs with zeros\n",
    "#             total_outputs = None\n",
    "#             context_from_last = None\n",
    "\n",
    "#             # Initialize a mask to track which sentences are finished\n",
    "#             finished_sentences_mask = torch.zeros(flattened_patches.size(0), dtype=torch.bool, device=flattened_patches.device)\n",
    "\n",
    "#             for iteration in range(MAX_N_CHUNKS_PER_SENTENCE):\n",
    "\n",
    "#                 generate_args = {\n",
    "#                     \"flattened_patches\": flattened_patches[~finished_sentences_mask],\n",
    "#                     \"attention_mask\": attention_mask[~finished_sentences_mask],\n",
    "#                     \"max_new_tokens\": CHUNK_LENGTH - (CONTEXT_OVERLAP_LENGTH if iteration else 0),\n",
    "#                 }\n",
    "\n",
    "#                 if iteration and context_from_last is not None:\n",
    "#                     generate_args[\"decoder_input_ids\"] = context_from_last[~finished_sentences_mask]\n",
    "\n",
    "#                 outputs = model.generate(**generate_args)\n",
    "\n",
    "#                 # Remove context overlap only from the second iteration onwards\n",
    "#                 new_chunks = outputs if iteration == 0 else outputs[:, CONTEXT_OVERLAP_LENGTH:]\n",
    "\n",
    "#                 if iteration == 0:\n",
    "#                     total_outputs = new_chunks\n",
    "#                 else:\n",
    "#                     # Update total_outputs by concatenating new chunks\n",
    "#                     new_chunks_with_padding_chunks = torch.full((flattened_patches.shape[0], new_chunks.shape[1]), PAD_TOKEN_ID, dtype=new_chunks.dtype, device=new_chunks.device)\n",
    "#                     new_chunks_with_padding_chunks[~finished_sentences_mask] = new_chunks\n",
    "#                     total_outputs = torch.cat((total_outputs, new_chunks_with_padding_chunks), dim=1)\n",
    "\n",
    "#                 # Update the finished_sentences_mask\n",
    "#                 finished_sentences_mask[~finished_sentences_mask] |= (outputs == processor.tokenizer.eos_token_id).any(dim=1)\n",
    "\n",
    "#                 # If all sentences are finished, exit the loop\n",
    "#                 if finished_sentences_mask.all():\n",
    "#                     break\n",
    "\n",
    "#                 if outputs.shape[1] < CHUNK_LENGTH:\n",
    "#                     print(\"ERROR: !! should have already exited because all sentences reached the end!!\")\n",
    "\n",
    "#                 # -1 because it will put in front a START_TOKEN automatically\n",
    "#                 context_from_last = total_outputs[:, -(CONTEXT_OVERLAP_LENGTH-1):]\n",
    "\n",
    "#             predictions = processor.tokenizer.batch_decode(total_outputs, skip_special_tokens=True)\n",
    "\n",
    "#             labels[labels == -100] = 0\n",
    "#             answers = processor.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "#             bleu_scores += [corpus_bleu([[answer]], [pred], smoothing_function=SmoothingFunction().method4) for pred, answer in zip(predictions, answers)]\n",
    "\n",
    "#             avg_bleu_score = np.mean(bleu_scores)\n",
    "#             test_loop.set_postfix(bleu_score=avg_bleu_score)\n",
    "\n",
    "#             if config.get(\"verbose\", False):\n",
    "#                 for pred, answer, bleu_score in zip(predictions, answers, bleu_scores):\n",
    "#                     tqdm.write(f\"\\nPrediction: {pred}\\n    Answer: {answer}\\n      Bleu: {bleu_score:.2f}\")\n",
    "\n",
    "\n",
    "#     return avg_bleu_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "GhiWvFFFA8n4"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, scheduler, epoch, global_step, wandb_run_id, avg_bleu_score, experiment_name, folder_path):\n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "        \"global_step\": global_step,\n",
    "        'wandb_run_id': wandb_run_id\n",
    "    }\n",
    "    model_name = f\"{experiment_name}_epoch[{epoch}]_bleu[{avg_bleu_score:.2f}].pth\"\n",
    "    torch.save(checkpoint, folder_path + model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "F6Lme6odJJK8"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "          \"batch_size\": BATCH_SIZE,\n",
    "          \"num_warmup_steps\": NUM_WARMUP_STEPS,\n",
    "          \"max_epochs\": MAX_EPOCHS,\n",
    "          \"lr\": LR,\n",
    "          \"check_val_every_n_epoch\": CHECK_VAL_EVERY_N_EPOCH,\n",
    "          \"gradient_clip_val\": GRADIENT_CLIP_VAL,\n",
    "          \"accumulate_grad_batches\": ACCUMULATE_GRAD_BATCHES,\n",
    "          \"verbose\": VERBOSE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "QxemWk5nEfZL"
   },
   "outputs": [],
   "source": [
    "def validate_config(config):\n",
    "    # Check required keys\n",
    "    required_keys = [\n",
    "        \"batch_size\",\n",
    "        \"num_warmup_steps\",\n",
    "        \"max_epochs\",\n",
    "        \"lr\",\n",
    "        \"check_val_every_n_epoch\",\n",
    "        \"gradient_clip_val\",\n",
    "        \"accumulate_grad_batches\",\n",
    "        \"verbose\"\n",
    "    ]\n",
    "    for key in required_keys:\n",
    "        if key not in config:\n",
    "            raise ValueError(f\"Key '{key}' must be present in the configuration.\")\n",
    "\n",
    "    # Check that values are in expected ranges\n",
    "    if config[\"batch_size\"] <= 0:\n",
    "        raise ValueError(\"batch_size must be positive.\")\n",
    "    if config[\"num_warmup_steps\"] < 0:\n",
    "        raise ValueError(\"num_warmup_steps must be non-negative.\")\n",
    "    if config[\"max_epochs\"] <= 0:\n",
    "        raise ValueError(\"max_epochs must be positive.\")\n",
    "    if config[\"lr\"] <= 0:\n",
    "        raise ValueError(\"Learning rate must be positive.\")\n",
    "    if config[\"check_val_every_n_epoch\"] <= 0:\n",
    "        raise ValueError(\"check_val_every_n_epoch must be positive.\")\n",
    "    if config[\"gradient_clip_val\"] < 0:\n",
    "        raise ValueError(\"gradient_clip_val must be non-negative.\")\n",
    "    if config[\"accumulate_grad_batches\"] <= 0:\n",
    "        raise ValueError(\"accumulate_grad_batches must be positive.\")\n",
    "    if not isinstance(config[\"verbose\"], bool):\n",
    "        raise ValueError(\"verbose must be a boolean value.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knzzKEtwEruj",
    "outputId": "b03c40ce-ae8e-4cfd-88c7-b11bc776922d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 4, 'num_warmup_steps': 1000, 'max_epochs': 200, 'lr': 0.0001, 'check_val_every_n_epoch': 5, 'gradient_clip_val': 1.0, 'accumulate_grad_batches': 2.0, 'verbose': True}\n"
     ]
    }
   ],
   "source": [
    "validate_config(config)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('checkpointsPix2Struct_SynthBootstrap_1000_Complete_epoch[19]_bleu[0.87].pth')\n",
    "# print(\"Saved WandB run ID:\", checkpoint['wandb_run_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EPfNUdrEoci8",
    "outputId": "06495bdb-c700-4788-892a-6e0e67c1a1f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-Pix2Struct_SynthBootstrap</strong> at: <a href='https://wandb.ai/seyeon-michigan-state-university/Pix2Struct/runs/a6k3hxp0' target=\"_blank\">https://wandb.ai/seyeon-michigan-state-university/Pix2Struct/runs/a6k3hxp0</a><br> View project at: <a href='https://wandb.ai/seyeon-michigan-state-university/Pix2Struct' target=\"_blank\">https://wandb.ai/seyeon-michigan-state-university/Pix2Struct</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250414_101836-a6k3hxp0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/ffs24/home/seyeon/wandb/run-20250414_101921-iymkxnbk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seyeon-michigan-state-university/Pix2Struct/runs/iymkxnbk' target=\"_blank\">run-Pix2Struct_SynthBootstrap</a></strong> to <a href='https://wandb.ai/seyeon-michigan-state-university/Pix2Struct' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seyeon-michigan-state-university/Pix2Struct' target=\"_blank\">https://wandb.ai/seyeon-michigan-state-university/Pix2Struct</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seyeon-michigan-state-university/Pix2Struct/runs/iymkxnbk' target=\"_blank\">https://wandb.ai/seyeon-michigan-state-university/Pix2Struct/runs/iymkxnbk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/199 - train loop:   0%|          | 0/692 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.cuda.FloatTensor{[4, 4, 1, 1024, 1024]}, size=[4, 1, 1024, 1024]): the number of sizes provided (4) must be greater or equal to the number of dimensions in the tensor (5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 38\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(config, processor, model, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     36\u001b[0m epoch_last \u001b[38;5;241m=\u001b[39m epoch_start \u001b[38;5;241m+\u001b[39m max_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch_start, epoch_start \u001b[38;5;241m+\u001b[39m max_epochs):\n\u001b[0;32m---> 38\u001b[0m     global_step, moving_avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_last\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m+\u001b[39m epoch_start \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m epoch_last \u001b[38;5;129;01mor\u001b[39;00m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_val_every_n_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     41\u001b[0m         avg_bleu_score \u001b[38;5;241m=\u001b[39m testing_loop(val_dataloader, model, processor, config, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_last\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - valid loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[42], line 21\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(epoch, train_dataloader, model, config, optimizer, scheduler, global_step, epoch_last)\u001b[0m\n\u001b[1;32m     18\u001b[0m decoder_input_ids, decoder_attention_mask \u001b[38;5;241m=\u001b[39m get_decoder_input_ids_and_attention_mask(labels, part)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# outputs = model(labels=labels, flattened_patches=flattened_patches, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids, decoder_attention_mask=decoder_attention_mask)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflattened_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflattened_patches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/pix2struct/modeling_pix2struct.py:1870\u001b[0m, in \u001b[0;36mPix2StructForConditionalGeneration.forward\u001b[0;34m(self, flattened_patches, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, labels, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1867\u001b[0m     decoder_attention_mask[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1870\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1871\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1873\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/pix2struct/modeling_pix2struct.py:1446\u001b[0m, in \u001b[0;36mPix2StructTextModel.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, labels, return_dict, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(batch_size, mask_seq_length, device\u001b[38;5;241m=\u001b[39minputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_decoder:\n\u001b[0;32m-> 1446\u001b[0m     causal_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_causal_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1448\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1451\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1454\u001b[0m     causal_mask \u001b[38;5;241m=\u001b[39m attention_mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/pix2struct/modeling_pix2struct.py:1634\u001b[0m, in \u001b[0;36mPix2StructTextModel._update_causal_mask\u001b[0;34m(self, attention_mask, input_tensor, cache_position, past_key_values, output_attentions)\u001b[0m\n\u001b[1;32m   1627\u001b[0m     target_length \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1628\u001b[0m         attention_mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1629\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attention_mask, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m   1630\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m past_seen_tokens \u001b[38;5;241m+\u001b[39m sequence_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1631\u001b[0m     )\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;66;03m# In case the provided `attention` mask is 2D, we generate a causal mask here (4D).\u001b[39;00m\n\u001b[0;32m-> 1634\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_4d_causal_attention_mask_with_cache_position\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_attn_implementation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msdpa\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1646\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;66;03m# using left padding. This is required by F.scaled_dot_product_attention memory-efficient attention path.\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m     \u001b[38;5;66;03m# Details: https://github.com/pytorch/pytorch/issues/110213\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m     min_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfinfo(dtype)\u001b[38;5;241m.\u001b[39mmin\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/pix2struct/modeling_pix2struct.py:1711\u001b[0m, in \u001b[0;36mPix2StructTextModel._prepare_4d_causal_attention_mask_with_cache_position\u001b[0;34m(attention_mask, sequence_length, target_length, dtype, device, cache_position, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m   1707\u001b[0m         padding_mask \u001b[38;5;241m=\u001b[39m causal_mask[:, :, :, :mask_length] \u001b[38;5;241m+\u001b[39m attention_mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1708\u001b[0m             causal_mask\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m   1709\u001b[0m         )\n\u001b[1;32m   1710\u001b[0m         padding_mask \u001b[38;5;241m=\u001b[39m padding_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1711\u001b[0m         \u001b[43mcausal_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mmask_length\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m causal_mask[:, :, :, :mask_length]\u001b[38;5;241m.\u001b[39mmasked_fill(\n\u001b[1;32m   1712\u001b[0m             padding_mask, min_dtype\n\u001b[1;32m   1713\u001b[0m         )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m causal_mask\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.cuda.FloatTensor{[4, 4, 1, 1024, 1024]}, size=[4, 1, 1024, 1024]): the number of sizes provided (4) must be greater or equal to the number of dimensions in the tensor (5)"
     ]
    }
   ],
   "source": [
    "train_model(config, processor, model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06a1c9b06e104cc0804d0b6c217e2997": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f10bb55ee654fb7a89868ae347d7514": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0f5444713b094d54ad7e9b613ab12d25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10d06787e2b34435bdd33e549a980aee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10e915f0c9e24a6e953203bd0283f094": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11c38a1ceff94799b52f5e0ae8b84969": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15e38778004b42b1aed4e42e05e6b9e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7aef95b240a24ba482ff25d1ff1bbc39",
      "max": 2201,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec408e1374314eaeb222569c653fcb2c",
      "value": 2201
     }
    },
    "161589ef49a64926834eada256388668": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1621b516d9ec41f9b0dc0f3b7e23feb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2375fafdc51c4616ad42de83731cb051",
      "placeholder": "​",
      "style": "IPY_MODEL_54a1747a9bd04718958c2ce6082547a3",
      "value": "Downloading (…)cial_tokens_map.json: 100%"
     }
    },
    "191b60c5726c4002a93e0d622c2b0698": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ddb3ecbc2e743438926f3e088659976": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f1c33aa528e4a43bfb298957cfe2fee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fb50697ceff45aeb2d8cac2cee2c22c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e8222a9fb844ab59eb9251ee5e9cd92",
      "max": 3265159,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f10bb55ee654fb7a89868ae347d7514",
      "value": 3265159
     }
    },
    "2375fafdc51c4616ad42de83731cb051": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ebc30057a344280b18311f35d148323": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f5444713b094d54ad7e9b613ab12d25",
      "placeholder": "​",
      "style": "IPY_MODEL_10d06787e2b34435bdd33e549a980aee",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "30052275c23c46419b8514b32e0d00bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "31779c12e1504311aa481206c83a2163": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "340e901240d645fabc7766cc6bfe66d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38271e0f9f6f41958163672d0201d6ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d45d65b44fca4b8b8d5ba0ab653cc1fa",
       "IPY_MODEL_4bc5323f5ffa4891ae7ac3a361489e6e",
       "IPY_MODEL_e4511bb6e56c46b8a1daef8e3275442a"
      ],
      "layout": "IPY_MODEL_95329f0d24984b40aa7eb82114bf5591"
     }
    },
    "39888333744e4904b07b40a6ed8dfce6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44a0c75207414dadb7eaec22678391e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "49f2463952c242d48150894057246cf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b62856cbf364e8e832d46d8cfa51b0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6675867d1a0641a08a808f134c30f6ea",
       "IPY_MODEL_6539bb1b685b4ef5b19bf6753c00cdc3",
       "IPY_MODEL_70fe49be4d92429b9bce8023dfd07961"
      ],
      "layout": "IPY_MODEL_340e901240d645fabc7766cc6bfe66d4"
     }
    },
    "4bc5323f5ffa4891ae7ac3a361489e6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9c593d7ee604fa19d7c58414facad54",
      "max": 1129238081,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fe96538b9f4c452c90ca4cbca734b9fc",
      "value": 1129238081
     }
    },
    "4c399af2dafe432f87fd4546616bab47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4cba271698ee4905b98d962ae715a9d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4cc0dd0670054510b8e8b06756fff6a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e8222a9fb844ab59eb9251ee5e9cd92": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52b56e2fa97147acaf348b050be63550": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54a1747a9bd04718958c2ce6082547a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54be443c0c9e441296dd7cdf67db46aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59ce1cc6421949aeb6994bccacafd2a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52b56e2fa97147acaf348b050be63550",
      "placeholder": "​",
      "style": "IPY_MODEL_54be443c0c9e441296dd7cdf67db46aa",
      "value": "Downloading spiece.model: 100%"
     }
    },
    "5ac6a0c5f3884a97a668bd94e2c99247": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_737c072add7e4216bd0edb23f70dfaf3",
      "max": 231,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30052275c23c46419b8514b32e0d00bb",
      "value": 231
     }
    },
    "5d1234c1b99d4348b798183b3bf42990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e63695c36bb43068e7405a2a4230255": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f62f8a1831743f3ab7d54ab6dffbd76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63da399945314f728f3e3bc83b515bc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_88edc231537a478dbc3d2813519fd21f",
       "IPY_MODEL_fb7588cb84334eebbe741c2a74087267",
       "IPY_MODEL_d807979736ac4efb88adfe885df15b0a"
      ],
      "layout": "IPY_MODEL_5e63695c36bb43068e7405a2a4230255"
     }
    },
    "6539bb1b685b4ef5b19bf6753c00cdc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_980b66fd9db94e6387e2a3695266dcd2",
      "max": 2613,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31779c12e1504311aa481206c83a2163",
      "value": 2613
     }
    },
    "6675867d1a0641a08a808f134c30f6ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_faba4ea1b56d433bbb7c7ffa622563da",
      "placeholder": "​",
      "style": "IPY_MODEL_11c38a1ceff94799b52f5e0ae8b84969",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "70fe49be4d92429b9bce8023dfd07961": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49f2463952c242d48150894057246cf6",
      "placeholder": "​",
      "style": "IPY_MODEL_cc74223b6eb24b8f91e8c291adb8f02a",
      "value": " 2.61k/2.61k [00:00&lt;00:00, 215kB/s]"
     }
    },
    "737c072add7e4216bd0edb23f70dfaf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75ceaa2e86914cf392de027b89e8db1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39888333744e4904b07b40a6ed8dfce6",
      "placeholder": "​",
      "style": "IPY_MODEL_4cba271698ee4905b98d962ae715a9d4",
      "value": "Downloading (…)rocessor_config.json: 100%"
     }
    },
    "7a61dc6ad0c848168e4a68cc0970aebf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7aef95b240a24ba482ff25d1ff1bbc39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7faf095de4ea48a08ad56742ffd6311f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8161314abb844376b605c9b2e1b5f9fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8743786ccb424b1d805912ed49b5d2ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59ce1cc6421949aeb6994bccacafd2a6",
       "IPY_MODEL_c610f62ad52b43cfbf829d22d09c3ec4",
       "IPY_MODEL_a164951cb80a4077b5a96ea73ba360eb"
      ],
      "layout": "IPY_MODEL_fcb5645709fd4d3b8715ddee208e0223"
     }
    },
    "8760eb617eb2439fba4a92273f3bca56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10e915f0c9e24a6e953203bd0283f094",
      "placeholder": "​",
      "style": "IPY_MODEL_5d1234c1b99d4348b798183b3bf42990",
      "value": " 2.20k/2.20k [00:00&lt;00:00, 211kB/s]"
     }
    },
    "88b0140c32e140339325d6eae0880ebd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88edc231537a478dbc3d2813519fd21f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf8c028c3b1a434fa5cfb3a2498d8403",
      "placeholder": "​",
      "style": "IPY_MODEL_ac4dc770d30844ea8a225714653ad2a6",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "95329f0d24984b40aa7eb82114bf5591": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "980b66fd9db94e6387e2a3695266dcd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "997cf585fc654ae38ad04a196b1c78d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1621b516d9ec41f9b0dc0f3b7e23feb7",
       "IPY_MODEL_15e38778004b42b1aed4e42e05e6b9e1",
       "IPY_MODEL_8760eb617eb2439fba4a92273f3bca56"
      ],
      "layout": "IPY_MODEL_4cc0dd0670054510b8e8b06756fff6a3"
     }
    },
    "a003c848e5c7459d8003a9da6628994d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a15823da8b6f4de88720c7e8d583ad55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_75ceaa2e86914cf392de027b89e8db1a",
       "IPY_MODEL_5ac6a0c5f3884a97a668bd94e2c99247",
       "IPY_MODEL_a7482b7279d54b6aba4dc07d8f68694a"
      ],
      "layout": "IPY_MODEL_c432eca2b0174148bc416e77f77c32b6"
     }
    },
    "a164951cb80a4077b5a96ea73ba360eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_191b60c5726c4002a93e0d622c2b0698",
      "placeholder": "​",
      "style": "IPY_MODEL_a748bdd7655247b9b77057e77149922a",
      "value": " 851k/851k [00:00&lt;00:00, 41.0MB/s]"
     }
    },
    "a2054c99644a46a7ae2c6082ded87f88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7482b7279d54b6aba4dc07d8f68694a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2054c99644a46a7ae2c6082ded87f88",
      "placeholder": "​",
      "style": "IPY_MODEL_1ddb3ecbc2e743438926f3e088659976",
      "value": " 231/231 [00:00&lt;00:00, 21.1kB/s]"
     }
    },
    "a748bdd7655247b9b77057e77149922a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab4cea35df204af0911ffeaff9608f43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06a1c9b06e104cc0804d0b6c217e2997",
      "placeholder": "​",
      "style": "IPY_MODEL_fb7fad66696542d3a18d1333221d3427",
      "value": " 3.27M/3.27M [00:01&lt;00:00, 2.78MB/s]"
     }
    },
    "ac4dc770d30844ea8a225714653ad2a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0e0482079c048a3847b3043fd430ec3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c432eca2b0174148bc416e77f77c32b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c610f62ad52b43cfbf829d22d09c3ec4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0e0482079c048a3847b3043fd430ec3",
      "max": 851388,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c399af2dafe432f87fd4546616bab47",
      "value": 851388
     }
    },
    "c9c593d7ee604fa19d7c58414facad54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc74223b6eb24b8f91e8c291adb8f02a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf8c028c3b1a434fa5cfb3a2498d8403": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d45d65b44fca4b8b8d5ba0ab653cc1fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a61dc6ad0c848168e4a68cc0970aebf",
      "placeholder": "​",
      "style": "IPY_MODEL_1f1c33aa528e4a43bfb298957cfe2fee",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "d807979736ac4efb88adfe885df15b0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8161314abb844376b605c9b2e1b5f9fb",
      "placeholder": "​",
      "style": "IPY_MODEL_88b0140c32e140339325d6eae0880ebd",
      "value": " 4.92k/4.92k [00:00&lt;00:00, 434kB/s]"
     }
    },
    "df22ab40b1054b9d905a62a420ce5348": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ebc30057a344280b18311f35d148323",
       "IPY_MODEL_1fb50697ceff45aeb2d8cac2cee2c22c",
       "IPY_MODEL_ab4cea35df204af0911ffeaff9608f43"
      ],
      "layout": "IPY_MODEL_161589ef49a64926834eada256388668"
     }
    },
    "e4511bb6e56c46b8a1daef8e3275442a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a003c848e5c7459d8003a9da6628994d",
      "placeholder": "​",
      "style": "IPY_MODEL_7faf095de4ea48a08ad56742ffd6311f",
      "value": " 1.13G/1.13G [00:02&lt;00:00, 469MB/s]"
     }
    },
    "ec408e1374314eaeb222569c653fcb2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "faba4ea1b56d433bbb7c7ffa622563da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb7588cb84334eebbe741c2a74087267": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f62f8a1831743f3ab7d54ab6dffbd76",
      "max": 4918,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_44a0c75207414dadb7eaec22678391e4",
      "value": 4918
     }
    },
    "fb7fad66696542d3a18d1333221d3427": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcb5645709fd4d3b8715ddee208e0223": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe96538b9f4c452c90ca4cbca734b9fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
